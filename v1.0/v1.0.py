#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSON to XODR Quality Checker
è´¨æ£€åˆä½œæ–¹çš„JSONè½¬XODRä»£ç å·¥å…·
"""

import json
import xml.etree.ElementTree as ET
import numpy as np
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import math
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.colors import ListedColormap


@dataclass
class QualityReport:
    """è´¨æ£€æŠ¥å‘Šæ•°æ®ç»“æ„"""
    completeness_score: float = 0.0
    consistency_score: float = 0.0
    warnings: List[str] = None
    details: Dict[str, Any] = None

    def __post_init__(self):
        if self.warnings is None:
            self.warnings = []
        if self.details is None:
            self.details = {}


class QualityChecker:
    """JSONè½¬XODRè´¨æ£€å·¥å…·ä¸»ç±»"""

    def __init__(self, json_file: str, xodr_file: str, threshold: float = 0.1):
        """
        åˆå§‹åŒ–è´¨æ£€å™¨

        Args:
            json_file: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
            xodr_file: è¾“å‡ºXODRæ–‡ä»¶è·¯å¾„
            threshold: åç§»é˜ˆå€¼(ç±³)ï¼Œé»˜è®¤0.1m(10cm)
        """
        self.json_file = Path(json_file)
        self.xodr_file = Path(xodr_file)
        self.threshold = threshold

        # åŠ è½½æ•°æ®
        self.json_data = self._load_json()
        self.xodr_data = self._load_xodr()

        # åˆå§‹åŒ–æŠ¥å‘Š
        self.report = QualityReport()

    def _load_json(self) -> Dict:
        """åŠ è½½JSONæ•°æ®"""
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½JSONæ–‡ä»¶: {self.json_file}")
            return data
        except Exception as e:
            raise ValueError(f"âŒ æ— æ³•åŠ è½½JSONæ–‡ä»¶ {self.json_file}: {e}")

    def _load_xodr(self) -> ET.Element:
        """åŠ è½½XODRæ•°æ®"""
        try:
            tree = ET.parse(self.xodr_file)
            root = tree.getroot()
            print(f"âœ… æˆåŠŸåŠ è½½XODRæ–‡ä»¶: {self.xodr_file}")
            return root
        except Exception as e:
            raise ValueError(f"âŒ æ— æ³•åŠ è½½XODRæ–‡ä»¶ {self.xodr_file}: {e}")

    def check_completeness(self) -> float:
        """
        æ£€æŸ¥å…ƒç´ å®Œæ•´æ€§
        å¯¹æ¯”JSONè¾“å…¥å’ŒXODRè¾“å‡ºçš„å…³é”®å…ƒç´ æ•°é‡
        """
        print("\nğŸ” å¼€å§‹å…ƒç´ å®Œæ•´æ€§æ£€æŸ¥...")

        completeness_details = {}
        total_score = 0
        check_count = 0

        # 1. æ£€æŸ¥è½¦é“æ•°é‡
        json_lanes = len(self.json_data.get('lanes', []))
        xodr_lanes = self._count_xodr_lanes()

        lane_score = min(xodr_lanes / json_lanes, 1.0) if json_lanes > 0 else 1.0
        completeness_details['lanes'] = {
            'json_count': json_lanes,
            'xodr_count': xodr_lanes,
            'score': lane_score
        }
        total_score += lane_score
        check_count += 1

        # 2. æ£€æŸ¥è¾¹ç•Œæ•°é‡
        json_bounds = len(self.json_data.get('bounds', []))
        xodr_road_marks = self._count_xodr_road_marks()

        bound_score = min(xodr_road_marks / (json_bounds * 2),
                          1.0) if json_bounds > 0 else 1.0  # ä¹˜ä»¥2å› ä¸ºæ¯ä¸ªboundå¯èƒ½æœ‰å¤šä¸ªlane_mark
        completeness_details['bounds'] = {
            'json_count': json_bounds,
            'xodr_count': xodr_road_marks,
            'score': bound_score
        }
        total_score += bound_score
        check_count += 1

        # 3. æ£€æŸ¥ç‰©ä½“æ•°é‡
        json_objects = len(self.json_data.get('objects', []))
        xodr_objects = self._count_xodr_objects()

        object_score = min(xodr_objects / json_objects, 1.0) if json_objects > 0 else 1.0
        completeness_details['objects'] = {
            'json_count': json_objects,
            'xodr_count': xodr_objects,
            'score': object_score
        }
        total_score += object_score
        check_count += 1

        # è®¡ç®—æ€»ä½“å®Œæ•´æ€§å¾—åˆ†
        self.report.completeness_score = total_score / check_count if check_count > 0 else 0
        self.report.details['completeness'] = completeness_details

        print(f"ğŸ“Š å®Œæ•´æ€§æ£€æŸ¥å®Œæˆï¼Œæ€»ä½“å¾—åˆ†: {self.report.completeness_score:.2%}")
        return self.report.completeness_score

    def check_curve_consistency(self) -> float:
        """
        æ£€æŸ¥æ›²çº¿ä¸€è‡´æ€§ï¼šä»…å¯¹ JSON çš„è¾¹ç•Œç‚¹ï¼ˆboundsï¼‰è®¡ç®—åˆ° XODRï¼ˆå‚è€ƒçº¿+è½¦é“è¾¹ç•Œï¼‰çš„æœ€è¿‘è·ç¦»ã€‚
        å¿½ç•¥ JSON objectsã€‚
        """
        print("\nğŸ” å¼€å§‹æ›²çº¿ä¸€è‡´æ€§æ£€æŸ¥...")

        warnings = []

        # JSON ç‚¹ï¼šä»…ä¿ç•™ bounds
        all_json_points = self._get_all_json_points()
        bound_points = [p for p in all_json_points if p.get('source') == 'bound']
        ignored_objects = len(all_json_points) - len(bound_points)

        # XODR ç‚¹ï¼ˆå‚è€ƒçº¿ + è½¦é“è¾¹ç•Œï¼‰
        xodr_data = self._sample_xodr_curves_and_lanes()
        xodr_points = []
        xodr_points.extend(xodr_data.get("reference_lines", []))
        xodr_points.extend(xodr_data.get("lane_boundaries", []))

        print(f"   ğŸ“ JSONè¾¹ç•Œç‚¹æ•°: {len(bound_points)}  (objects å·²å¿½ç•¥: {ignored_objects})")
        print(f"   ğŸ“ XODRé‡‡æ ·ç‚¹æ•°: {len(xodr_points)} "
              f"(ref: {len(xodr_data.get('reference_lines', []))}, "
              f"lanes: {len(xodr_data.get('lane_boundaries', []))})")

        if not bound_points or not xodr_points:
            print("   âŒ æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ä¸€è‡´æ€§")
            self.report.consistency_score = 0.0
            self.report.details['consistency'] = {
                'average_deviation': 0.0, 'max_deviation': 0.0, 'min_deviation': 0.0,
                'point_count': len(bound_points), 'threshold': self.threshold,
                'warnings_count': 0, 'points_over_threshold': 0
            }
            return 0.0

        # è®¡ç®—åç§»ï¼ˆä»… boundsï¼‰
        deviations = []
        for i, json_point in enumerate(bound_points):
            d = self._find_nearest_distance_to_xodr(json_point, xodr_points)
            deviations.append(d)
            if d > self.threshold:
                warnings.append(
                    f"âš ï¸ åæ ‡ç‚¹ ({json_point['x']:.1f}, {json_point['y']:.1f}) "
                    f"åç§»è¶…è¿‡é˜ˆå€¼: {d:.3f}m > {self.threshold}m"
                )
            if (i + 1) % 100 == 0 or i == len(bound_points) - 1:
                print(f"   ğŸ“Š å·²å¤„ç† {i + 1}/{len(bound_points)} ä¸ªç‚¹")

        avg_dev = float(np.mean(deviations)) if deviations else 0.0
        max_dev = float(np.max(deviations)) if deviations else 0.0
        min_dev = float(np.min(deviations)) if deviations else 0.0
        over = sum(1 for d in deviations if d > self.threshold)

        # åˆ†æ•°ï¼š1 - å¹³å‡åç§»/é˜ˆå€¼ï¼ˆä¸‹é™ 0ï¼‰
        consistency_score = max(0.0, 1.0 - (avg_dev / self.threshold)) if self.threshold > 0 else 0.0

        self.report.consistency_score = consistency_score
        self.report.warnings.extend(warnings)
        self.report.details['consistency'] = {
            'average_deviation': avg_dev,
            'max_deviation': max_dev,
            'min_deviation': min_dev,
            'point_count': len(bound_points),
            'threshold': self.threshold,
            'warnings_count': len(warnings),
            'points_over_threshold': over,
        }

        print(f"ğŸ“Š ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼Œå¾—åˆ†: {consistency_score:.2%}")
        print(f"ğŸ“Š å¹³å‡åç§»: {avg_dev:.3f}mï¼Œæœ€å¤§åç§»: {max_dev:.3f}mï¼Œæœ€å°åç§»: {min_dev:.3f}m")
        print(f"ğŸ“Š è¶…è¿‡é˜ˆå€¼çš„ç‚¹: {over}/{len(bound_points)}")

        return consistency_score

    def _get_all_json_points(self) -> List[Dict]:
        """è·å–JSONä¸­æ‰€æœ‰çš„åæ ‡ç‚¹"""
        all_points = []

        # ä»boundsä¸­æå–åæ ‡ç‚¹
        for bound in self.json_data.get('bounds', []):
            bound_id = bound['id']
            for pt in bound['pts']:
                point = {
                    'x': pt['x'],
                    'y': pt['y'],
                    'z': pt['z'],
                    'bound_id': bound_id,
                    'source': 'bound'
                }
                all_points.append(point)

        # ä¹Ÿå¯ä»¥ä»objectsä¸­æå–åæ ‡ç‚¹
        for obj in self.json_data.get('objects', []):
            obj_id = obj['id']
            for pt in obj.get('outline', []):
                point = {
                    'x': pt['x'],
                    'y': pt['y'],
                    'z': pt['z'],
                    'object_id': obj_id,
                    'source': 'object'
                }
                all_points.append(point)

        return all_points

    def _sample_xodr_curves_and_lanes(self, step: float = 0.05):
        """
        é‡‡æ ·å‚è€ƒçº¿ + è½¦é“(ä¸­å¿ƒçº¿/è¾¹ç•Œçº¿)ï¼Œå¹¶è¿”å›ï¼š
          - reference_lines: æ‰å¹³ç‚¹é›†ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
          - lane_boundaries: æ‰å¹³ç‚¹é›†ï¼ˆæ³¨æ„ï¼šç°åœ¨æ˜¯â€œè¾¹ç•Œçº¿â€æ‰€æœ‰ç‚¹ï¼Œéä¸­å¿ƒçº¿ï¼‰
          - reference_polylines: æ¯æ¡ road ä¸€æ¡å‚è€ƒçº¿ polyline
          - lane_polylines: æ¯æ¡è½¦é“çš„â€œä¸­å¿ƒçº¿â€ polylineï¼ˆç»˜å›¾ç”¨ï¼Œå…¼å®¹æ—§å­—æ®µåï¼‰
          - lane_center_polylines: åŒä¸Šï¼ˆæ˜¾å¼å‘½åï¼‰
          - lane_edge_polylines: æ¯æ¡è½¦é“çš„å†…/å¤–è¾¹ç•Œ polylineï¼ˆç»˜å›¾/åŒ¹é…å¯ç”¨ï¼‰
        """
        import xml.etree.ElementTree as ET
        import math
        import numpy as np

        tree = ET.parse(self.xodr_file)
        root = tree.getroot()

        out = {
            "reference_lines": [],
            "lane_boundaries": [],
            "reference_polylines": [],
            "lane_polylines": [],  # = center polylinesï¼ˆå…¼å®¹æ—§å­—æ®µåï¼‰
            "lane_center_polylines": [],
            "lane_edge_polylines": []  # [{"road_id","lane_id","side","kind":"inner"/"outer","points":[(x,y),...]}]
        }

        # ---------- å·¥å…· ----------
        def local_to_global(x0, y0, hdg, u, v):
            ch, sh = math.cos(hdg), math.sin(hdg)
            return x0 + ch * u - sh * v, y0 + sh * u + ch * v

        def sample_planview_polyline(plan_view, default_step=step):
            ref_pts = []  # [(s_abs, x, y)]
            s_abs = 0.0
            geoms = list(plan_view.findall('geometry'))
            for g in geoms:
                x0 = float(g.attrib["x"])
                y0 = float(g.attrib["y"])
                hdg = float(g.attrib["hdg"])
                L = float(g.attrib["length"])
                child = list(g)[0]
                tag = child.tag

                n = max(2, int(L / default_step) + 1)
                s_vals = np.linspace(0.0, L, n)

                if tag == "line":
                    for s in s_vals:
                        ref_pts.append((s_abs + s, *local_to_global(x0, y0, hdg, s, 0.0)))

                elif tag == "arc":
                    k = float(child.attrib["curvature"])
                    R = 1.0 / k if k != 0 else 1e12
                    for s in s_vals:
                        ang = k * s
                        u = R * math.sin(ang)
                        v = R * (1.0 - math.cos(ang))
                        ref_pts.append((s_abs + s, *local_to_global(x0, y0, hdg, u, v)))

                elif tag == "spiral":
                    c0 = float(child.attrib["curvStart"])
                    c1 = float(child.attrib["curvEnd"])
                    for s in s_vals:
                        c = c0 + (c1 - c0) * (s / L)
                        theta = 0.5 * c * s  # ç®€åŒ–
                        u = s * math.cos(theta)
                        v = s * math.sin(theta)
                        ref_pts.append((s_abs + s, *local_to_global(x0, y0, hdg, u, v)))

                elif tag == "paramPoly3":
                    aU = float(child.attrib.get("aU", 0))
                    bU = float(child.attrib.get("bU", 1))
                    cU = float(child.attrib.get("cU", 0))
                    dU = float(child.attrib.get("dU", 0))
                    aV = float(child.attrib.get("aV", 0))
                    bV = float(child.attrib.get("bV", 0))
                    cV = float(child.attrib.get("cV", 0))
                    dV = float(child.attrib.get("dV", 0))
                    p_range = child.attrib.get("pRange", "normalized")
                    t_vals = s_vals if p_range == "arcLength" else np.linspace(0.0, 1.0, len(s_vals))
                    for i, t in enumerate(t_vals):
                        u = aU + bU * t + cU * t * t + dU * t * t * t
                        v = aV + bV * t + cV * t * t + dV * t * t * t
                        ref_pts.append((s_abs + s_vals[i], *local_to_global(x0, y0, hdg, u, v)))
                s_abs += L
            return ref_pts

        def finite_diff_heading(xs, ys):
            th = []
            n = len(xs)
            for i in range(n):
                if i == 0:
                    dx, dy = xs[1] - xs[0], ys[1] - ys[0]
                elif i == n - 1:
                    dx, dy = xs[-1] - xs[-2], ys[-1] - ys[-2]
                else:
                    dx, dy = xs[i + 1] - xs[i - 1], ys[i + 1] - ys[i - 1]
                th.append(math.atan2(dy, dx) if dx * dx + dy * dy > 0 else 0.0)
            return th

        # laneWidth & laneOffset å¤šé¡¹å¼
        def width_poly_at(width_list, s_rel):
            if not width_list:
                return 0.0
            prev = width_list[0]
            for w in width_list:
                if w["sOffset"] <= s_rel:
                    prev = w
                else:
                    break
            ds = max(0.0, s_rel - prev["sOffset"])
            return prev["a"] + prev["b"] * ds + prev["c"] * ds * ds + prev["d"] * ds * ds * ds

        def parse_lane_sections(lanes_elem):
            sections = []
            for sec in lanes_elem.findall('laneSection'):
                s0 = float(sec.attrib['s'])
                left = sec.find('left')
                right = sec.find('right')
                one = {"s": s0, "left": [], "right": []}

                def collect(side_elem, side_name):
                    if side_elem is None:
                        return
                    for ln in side_elem.findall('lane'):
                        lid = ln.attrib.get('id', '')
                        widths = []
                        for w in ln.findall('width'):
                            widths.append({
                                "sOffset": float(w.attrib.get('sOffset', 0.0)),
                                "a": float(w.attrib.get('a', 0.0)),
                                "b": float(w.attrib.get('b', 0.0)),
                                "c": float(w.attrib.get('c', 0.0)),
                                "d": float(w.attrib.get('d', 0.0)),
                            })
                        widths.sort(key=lambda x: x["sOffset"])
                        one[side_name].append({"id": lid, "widths": widths})

                    # ä»ä¸­çº¿å‘å¤–æ’åºï¼ˆleft: +1,+2,...ï¼› right: -1,-2,... çš„ç»å¯¹å€¼å‡åºï¼‰
                    if side_name == "left":
                        one[side_name].sort(key=lambda e: int(e["id"]))
                    else:
                        one[side_name].sort(key=lambda e: abs(int(e["id"])))

                collect(left, "left");
                collect(right, "right")
                sections.append(one)
            sections.sort(key=lambda s: s["s"])
            return sections

        def parse_lane_offsets(lanes_elem):
            offsets = []
            for lo in lanes_elem.findall('laneOffset'):
                offsets.append({
                    "s": float(lo.attrib.get("s", 0.0)),
                    "a": float(lo.attrib.get("a", 0.0)),
                    "b": float(lo.attrib.get("b", 0.0)),
                    "c": float(lo.attrib.get("c", 0.0)),
                    "d": float(lo.attrib.get("d", 0.0)),
                })
            offsets.sort(key=lambda x: x["s"])
            return offsets

        def lane_offset_at(offsets, s_abs):
            if not offsets:
                return 0.0
            prev = offsets[0]
            for o in offsets:
                if o["s"] <= s_abs:
                    prev = o
                else:
                    break
            ds = max(0.0, s_abs - prev["s"])
            return prev["a"] + prev["b"] * ds + prev["c"] * ds * ds + prev["d"] * ds * ds * ds

        # ---------- ä¸»æµç¨‹ï¼šé€ road ----------
        for road in root.findall('.//road'):
            road_id = road.attrib.get('id', 'unknown')
            plan_view = road.find('planView')
            if plan_view is None:
                continue

            # 1) å‚è€ƒçº¿ polyline
            ref = sample_planview_polyline(plan_view)
            if len(ref) < 2:
                continue
            s_arr = [p[0] for p in ref]
            x_arr = [p[1] for p in ref]
            y_arr = [p[2] for p in ref]
            th_arr = finite_diff_heading(x_arr, y_arr)

            ref_poly = [(x_arr[i], y_arr[i]) for i in range(len(ref))]
            out["reference_polylines"].append(ref_poly)
            out["reference_lines"].extend(ref_poly)

            # 2) lanesï¼šä¸­å¿ƒçº¿ + è¾¹ç•Œçº¿
            lanes_elem = road.find('lanes')
            if lanes_elem is None:
                continue
            sections = parse_lane_sections(lanes_elem)
            offsets = parse_lane_offsets(lanes_elem)

            road_len = s_arr[-1]
            for si, sec in enumerate(sections):
                s0 = sec["s"]
                s1 = sections[si + 1]["s"] if si + 1 < len(sections) else road_len + 1e-6

                idxs = [i for i, sv in enumerate(s_arr) if (sv >= s0 and sv <= s1)]
                if len(idxs) < 2:
                    continue

                # ç´¯ç§¯å®¹å™¨ï¼škey -> pts
                centers = {}  # f"{side}:{lane_id}" -> [(x,y)]
                edges = {}  # f"{side}:{lane_id}:inner/outer" -> [(x,y)]

                def ensure(dct, key):
                    if key not in dct:
                        dct[key] = []
                    return dct[key]

                for i in idxs:
                    s_here = s_arr[i]
                    s_rel = s_here - s0
                    nx = -math.sin(th_arr[i]);
                    ny = math.cos(th_arr[i])  # å·¦æ³•å‘
                    base = lane_offset_at(offsets, s_here)

                    # ---- å·¦ä¾§ï¼šä»ä¸­çº¿å‘å¤– ----
                    cum = 0.0
                    for ln in sec["left"]:
                        w = width_poly_at(ln["widths"], s_rel)
                        inner_off = base + cum  # é è¿‘ä¸­çº¿çš„è¾¹ç•Œ
                        outer_off = inner_off + w  # è¿œç¦»ä¸­çº¿çš„è¾¹ç•Œ
                        center_off = inner_off + 0.5 * w

                        # è¾¹ç•Œç‚¹
                        ensure(edges, f"left:{ln['id']}:inner").append(
                            (x_arr[i] + inner_off * nx, y_arr[i] + inner_off * ny))
                        ensure(edges, f"left:{ln['id']}:outer").append(
                            (x_arr[i] + outer_off * nx, y_arr[i] + outer_off * ny))
                        # ä¸­å¿ƒç‚¹
                        ensure(centers, f"left:{ln['id']}").append(
                            (x_arr[i] + center_off * nx, y_arr[i] + center_off * ny))

                        cum += w

                    # ---- å³ä¾§ï¼šä»ä¸­çº¿å‘å¤–ï¼ˆè´Ÿæ–¹å‘ï¼‰----
                    cum = 0.0
                    for ln in sec["right"]:
                        w = width_poly_at(ln["widths"], s_rel)
                        inner_off = base - cum  # é è¿‘ä¸­çº¿çš„è¾¹ç•Œï¼ˆè´Ÿï¼‰
                        outer_off = inner_off - w  # è¿œç¦»ä¸­çº¿çš„è¾¹ç•Œï¼ˆæ›´è´Ÿï¼‰
                        center_off = inner_off - 0.5 * w

                        ensure(edges, f"right:{ln['id']}:inner").append(
                            (x_arr[i] + inner_off * nx, y_arr[i] + inner_off * ny))
                        ensure(edges, f"right:{ln['id']}:outer").append(
                            (x_arr[i] + outer_off * nx, y_arr[i] + outer_off * ny))
                        ensure(centers, f"right:{ln['id']}").append(
                            (x_arr[i] + center_off * nx, y_arr[i] + center_off * ny))

                        cum += w

                # å†™å‡ºæœ¬ section çš„æ›²çº¿
                for key, pts in centers.items():
                    side, lane_id = key.split(":")
                    out["lane_center_polylines"].append({
                        "road_id": road_id, "lane_id": lane_id, "side": side, "points": pts
                    })
                    out["lane_polylines"].append({  # å…¼å®¹åˆ«å
                        "road_id": road_id, "lane_id": lane_id, "side": side, "points": pts
                    })

                for key, pts in edges.items():
                    side, lane_id, kind = key.split(":")
                    out["lane_edge_polylines"].append({
                        "road_id": road_id, "lane_id": lane_id, "side": side, "kind": kind, "points": pts
                    })
                    # æ‰å¹³è¾¹ç•Œç‚¹ï¼ˆç”¨äºä¸€è‡´æ€§è®¡ç®—/æœ€è¿‘ç‚¹æœç´¢ï¼‰
                    out["lane_boundaries"].extend(pts)

        return out

    def _get_all_xodr_points(self) -> List[Tuple[float, float]]:
        """æŠŠå‚è€ƒçº¿ä¸è½¦é“è¾¹ç•Œåˆå¹¶æˆä¸€ä¸ª (x, y) ç‚¹åˆ—è¡¨"""
        data = self._sample_xodr_curves_and_lanes()
        points = []
        points.extend(data.get("reference_lines", []))
        points.extend(data.get("lane_boundaries", []))
        return points

    def _find_nearest_distance_to_xodr(self, json_point: Dict, xodr_points: List[Tuple[float, float]]) -> float:
        """æ‰¾åˆ°JSONç‚¹åˆ°XODRé‡‡æ ·ç‚¹çš„æœ€çŸ­è·ç¦»"""
        jx, jy = json_point['x'], json_point['y']

        min_distance = float('inf')
        for xodr_x, xodr_y in xodr_points:
            distance = math.sqrt((jx - xodr_x) ** 2 + (jy - xodr_y) ** 2)
            min_distance = min(min_distance, distance)

        return min_distance

    def visualize_point_matching(self, save_path: str = None) -> str:
        """
        ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼Œå¹¶è®°å½•åˆ° self._viz_pathï¼Œæ–¹ä¾¿ HTML æŠ¥å‘Šå¼•ç”¨
        """
        print("\nğŸ¨ Generating visualization charts...")

        all_json_points = self._get_all_json_points()
        xodr_sample_points = self._sample_xodr_curves_and_lanes()

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        self._plot_overall_distribution(ax1, all_json_points, xodr_sample_points)
        self._plot_deviation_analysis(ax2, all_json_points, xodr_sample_points)
        plt.tight_layout()

        if save_path is None:
            save_path = self.json_file.parent / f"{self.json_file.stem}_visualization.png"

        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… Visualization chart saved: {save_path}")

        # è®°å½•å›¾ç‰‡è·¯å¾„ï¼ˆæ–°å¢ï¼‰
        self._viz_path = str(save_path)

        try:
            plt.show()
        except:
            pass

        return str(save_path)

    def _plot_overall_distribution(self, ax, json_points, xodr_data):
        """
        å‚è€ƒçº¿(ç°) + æ¯æ¡è½¦é“ä¸­å¿ƒçº¿(å½©è‰²) + è¾¹ç•Œ(æµ…ç°è™šçº¿) + JSONç‚¹
        å¹¶åœ¨æ¯æ¡è½¦é“ä¸­å¿ƒçº¿çš„ä¸­ç‚¹æ ‡æ³¨ 'R{road} L{lane}'
        """
        import numpy as np
        import matplotlib.pyplot as plt

        # 1) å‚è€ƒçº¿
        ref_polys = xodr_data.get("reference_polylines", [])
        for poly in ref_polys:
            if len(poly) >= 2:
                xs, ys = zip(*poly)
                ax.plot(xs, ys, color='0.4', linewidth=1.5, alpha=0.7)
        if ref_polys:
            ax.plot([], [], color='0.4', linewidth=1.5, label=f'XODR reference ({sum(len(p) for p in ref_polys)})')

        # 2) è½¦é“è¾¹ç•Œï¼ˆæµ…ç°è™šçº¿ï¼Œè¾…åŠ©å¯¹é½è§‚å¯Ÿï¼‰
        edge_polys = xodr_data.get("lane_edge_polylines", [])
        for ed in edge_polys:
            pts = ed["points"]
            if len(pts) >= 2:
                xs, ys = zip(*pts)
                ax.plot(xs, ys, color='0.75', linewidth=0.8, alpha=0.6, linestyle='--')
        if edge_polys:
            ax.plot([], [], color='0.75', linewidth=0.8, linestyle='--',
                    label=f'XODR lane edges ({sum(len(e["points"]) for e in edge_polys)})')

        # 3) è½¦é“ä¸­å¿ƒçº¿ï¼ˆæ¯æ¡è½¦é“ç‹¬ç«‹ polyline + æ–‡æœ¬æ ‡æ³¨ï¼‰
        lane_polys = xodr_data.get("lane_center_polylines", xodr_data.get("lane_polylines", []))
        n_lane = len(lane_polys)
        if n_lane:
            colors = plt.cm.tab20(np.linspace(0, 1, max(20, n_lane)))  # é¢œè‰²è¶³å¤Ÿå¤š
        for i, lane in enumerate(lane_polys):
            pts = lane["points"]
            if len(pts) < 2:
                continue
            xs, ys = zip(*pts)
            ax.plot(xs, ys, linewidth=1.5, alpha=0.95, color=colors[i % len(colors)])

            # åœ¨çº¿ä¸­ç‚¹å¤„æ ‡æ³¨ï¼šR{road} L{lane_id}
            mid = len(pts) // 2
            tx, ty = pts[mid]
            txt = f"R{lane['road_id']} L{lane['lane_id']}"
            ax.text(tx, ty, txt, fontsize=8, alpha=0.85)

        if lane_polys:
            ax.plot([], [], linewidth=1.5, label=f'XODR lanes ({sum(len(l["points"]) for l in lane_polys)})')

        # 4) JSON ç‚¹
        bound_points = [p for p in json_points if p['source'] == 'bound']
        if bound_points:
            bx = [p['x'] for p in bound_points];
            by = [p['y'] for p in bound_points]
            ax.scatter(bx, by, s=30, alpha=0.85, label=f'JSON bounds ({len(bound_points)})')

        obj_points = [p for p in json_points if p['source'] == 'object']
        if obj_points:
            ox = [p['x'] for p in obj_points];
            oy = [p['y'] for p in obj_points]
            ax.scatter(ox, oy, s=30, alpha=0.85, label=f'JSON objects ({len(obj_points)})')

        ax.set_xlabel('X (m)');
        ax.set_ylabel('Y (m)')
        ax.set_title('JSON vs XODR Distribution')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.axis('equal')

    # éœ€è¦æ—¶ä¹Ÿå¯ä»¥ä¿ç•™ä¸€ä¸ªåˆ«å
    def _plot_distribution(self, ax, json_points, xodr_data):
        return self._plot_overall_distribution(ax, json_points, xodr_data)

    def _plot_deviation_analysis(self, ax, json_points: List[Dict], xodr_data: Dict):
        """Plot deviation analysisï¼ˆä»…å¯¹ bounds è®¡ç®—åç§»ï¼›objects ç½®ç°è¯´æ˜å¿½ç•¥ï¼‰"""

        # åˆå¹¶ XODR ç‚¹
        xodr_points = []
        if xodr_data["reference_lines"]:
            xodr_points.extend(xodr_data["reference_lines"])
        if xodr_data["lane_boundaries"]:
            xodr_points.extend(xodr_data["lane_boundaries"])

        # åˆ†ç¦» JSON
        bound_points = [p for p in json_points if p['source'] == 'bound']
        obj_points = [p for p in json_points if p['source'] == 'object']

        # åç§»ï¼ˆä»… boundsï¼‰
        deviations = []
        for p in bound_points:
            deviations.append(self._find_nearest_distance_to_xodr(p, xodr_points))

        # èƒŒæ™¯ XODR
        if xodr_points:
            xp, yp = zip(*xodr_points)
            ax.scatter(xp, yp, c='lightgray', s=5, alpha=0.3, label='XODR samples')

        # bounds ä»¥åç§»ç€è‰²
        if bound_points:
            bx = [p['x'] for p in bound_points];
            by = [p['y'] for p in bound_points]
            sc = ax.scatter(bx, by, c=deviations, s=50, cmap='RdYlGn_r',
                            alpha=0.9, edgecolors='black', linewidth=0.4, label=f'JSON bounds ({len(bound_points)})')
            cbar = plt.colorbar(sc, ax=ax);
            cbar.set_label('Deviation (m)')

            avg = np.mean(deviations) if deviations else 0.0
            stats_text = f"""Statistics:
        Total bound points: {len(bound_points)}
        Avg deviation: {avg:.3f}m
        Max deviation: {np.max(deviations) if deviations else 0:.3f}m
        Min deviation: {np.min(deviations) if deviations else 0:.3f}m
        Over threshold: {sum(1 for d in deviations if d > self.threshold)}/{len(deviations)}"""
            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
                    va='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.85))

        # objects ç½®ç°è¯´æ˜å¿½ç•¥
        if obj_points:
            ox = [p['x'] for p in obj_points];
            oy = [p['y'] for p in obj_points]
            ax.scatter(ox, oy, s=30, alpha=0.6, c='gray', label=f'JSON objects (ignored: {len(obj_points)})')

        ax.set_xlabel('X (m)');
        ax.set_ylabel('Y (m)')
        ax.set_title(f'Deviation Analysis (Avg: {np.mean(deviations) if deviations else 0:.3f}m)')
        ax.legend();
        ax.grid(True, alpha=0.3);
        ax.axis('equal')

    def analyze_matching_details(self, include_objects: bool = False) -> Dict:
        print("\nğŸ” Analyzing matching details...")

        all_json_points = self._get_all_json_points()
        if include_objects:
            use_points = all_json_points
        else:
            use_points = [p for p in all_json_points if p.get('source') == 'bound']

        xodr_data = self._sample_xodr_curves_and_lanes()
        xodr_sample_points = []
        xodr_sample_points.extend(xodr_data.get("reference_lines", []))
        xodr_sample_points.extend(xodr_data.get("lane_boundaries", []))

        analysis_results = {
            'total_json_points': len(use_points),
            'total_xodr_points': len(xodr_sample_points),
            'detailed_matches': []
        }

        print(f"\nğŸ“Š Detailed matching analysis:")
        print(f"{'Index':<5} {'Type':<6} {'JSON Coord':<20} {'Nearest XODR':<20} {'Dev(m)':<8} {'Status'}")
        print("-" * 80)

        for i, json_point in enumerate(use_points):
            min_distance = float('inf');
            nearest = None
            for xp, yp in xodr_sample_points:
                d = math.hypot(json_point['x'] - xp, json_point['y'] - yp)
                if d < min_distance:
                    min_distance = d;
                    nearest = (xp, yp)

            status = "âœ… Pass" if min_distance <= self.threshold else \
                ("âš ï¸ Warning" if min_distance <= self.threshold * 2 else "âŒ Fail")

            analysis_results['detailed_matches'].append({
                'index': i, 'json_point': json_point,
                'nearest_xodr_point': nearest, 'deviation': min_distance, 'status': status
            })

            if i < 20:
                jc = f"({json_point['x']:.1f}, {json_point['y']:.1f})"
                xc = f"({nearest[0]:.1f}, {nearest[1]:.1f})" if nearest else "None"
                src = json_point['source']
                print(f"{i:<5} {src:<6} {jc:<20} {xc:<20} {min_distance:<8.3f} {status}")
            elif i == 20:
                print("...")

        return analysis_results

    def _count_xodr_lanes(self) -> int:
        """ç»Ÿè®¡XODRä¸­çš„è½¦é“æ•°é‡"""
        count = 0
        for road in self.xodr_data.findall('.//road'):
            for lane in road.findall('.//lane'):
                if lane.get('type') == 'driving':  # åªç»Ÿè®¡è¡Œè½¦é“
                    count += 1
        return count

    def _count_xodr_road_marks(self) -> int:
        """ç»Ÿè®¡XODRä¸­çš„é“è·¯æ ‡è®°æ•°é‡"""
        return len(self.xodr_data.findall('.//roadMark'))

    def _count_xodr_objects(self) -> int:
        """ç»Ÿè®¡XODRä¸­çš„ç‰©ä½“æ•°é‡"""
        return len(self.xodr_data.findall('.//object'))

    def _extract_xodr_curves(self) -> List[Dict]:
        """ä»XODRä¸­æå–å‡ ä½•æ›²çº¿å‚æ•°ï¼ˆä¿ç•™ç”¨äºå…¶ä»–ç”¨é€”ï¼‰"""
        curves = []
        for road in self.xodr_data.findall('.//road'):
            road_id = road.get('id')
            for geometry in road.findall('.//geometry'):
                curve_data = {
                    'road_id': road_id,
                    's': float(geometry.get('s', 0)),
                    'x': float(geometry.get('x', 0)),
                    'y': float(geometry.get('y', 0)),
                    'hdg': float(geometry.get('hdg', 0)),
                    'length': float(geometry.get('length', 0))
                }

                # æå–paramPoly3å‚æ•°
                param_poly3 = geometry.find('paramPoly3')
                if param_poly3 is not None:
                    curve_data.update({
                        'aU': float(param_poly3.get('aU', 0)),
                        'bU': float(param_poly3.get('bU', 1)),
                        'cU': float(param_poly3.get('cU', 0)),
                        'dU': float(param_poly3.get('dU', 0)),
                        'aV': float(param_poly3.get('aV', 0)),
                        'bV': float(param_poly3.get('bV', 0)),
                        'cV': float(param_poly3.get('cV', 0)),
                        'dV': float(param_poly3.get('dV', 0))
                    })

                curves.append(curve_data)
        return curves

    def _evaluate_param_poly3(self, curve: Dict, t: float) -> Tuple[float, float]:
        """è®¡ç®—paramPoly3æ›²çº¿åœ¨å‚æ•°tå¤„çš„åæ ‡"""
        # paramPoly3å‚æ•°
        aU = curve.get('aU', 0)
        bU = curve.get('bU', 1)
        cU = curve.get('cU', 0)
        dU = curve.get('dU', 0)
        aV = curve.get('aV', 0)
        bV = curve.get('bV', 0)
        cV = curve.get('cV', 0)
        dV = curve.get('dV', 0)

        # è®¡ç®—å±€éƒ¨åæ ‡
        u = aU + bU * t + cU * t * t + dU * t * t * t
        v = aV + bV * t + cV * t * t + dV * t * t * t

        # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        x0, y0 = curve['x'], curve['y']
        hdg = curve['hdg']

        cos_hdg = math.cos(hdg)
        sin_hdg = math.sin(hdg)

        world_x = x0 + u * cos_hdg - v * sin_hdg
        world_y = y0 + u * sin_hdg + v * cos_hdg

        return world_x, world_y

    def generate_report(self, max_detail_rows: int = 200) -> str:
        """ç”Ÿæˆä¸­æ–‡ HTML è´¨æ£€æŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆè´¨æ£€æŠ¥å‘Š...")

        # åªåœ¨ details ç¼ºå¤±æ—¶è®¡ç®—ï¼Œé¿å…é‡å¤
        if 'completeness' not in self.report.details:
            self.check_completeness()
        if 'consistency' not in self.report.details:
            self.check_curve_consistency()

        # ä»…å¯¹ bounds åšåŒ¹é…æ˜ç»†ï¼ˆå¿½ç•¥ objectsï¼‰
        matching = self.analyze_matching_details(include_objects=False)

        # ç¡®ä¿å¯è§†åŒ–å›¾ç‰‡å­˜åœ¨
        viz_path = getattr(self, "_viz_path", None)
        if not viz_path or not Path(viz_path).exists():
            viz_path = self.visualize_point_matching()

        # ç»„ç»‡ç»™ HTML çš„æ•°æ®åŒ…
        data = {
            "json_file": str(self.json_file),
            "xodr_file": str(self.xodr_file),
            "threshold": self.threshold,
            "report": self.report,  # åŒ…å« completeness/consistency ä¸¤ä¸ªå—
            "matching": matching,  # åŒ¹é…æ˜ç»†
            "viz_path": str(viz_path),
            "max_detail_rows": max_detail_rows,
        }

        html_report = self._generate_html_report(data)

        report_file = self.json_file.parent / f"{self.json_file.stem}_quality_report.html"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_report)

        print(f"âœ… è´¨æ£€æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return str(report_file)

    def _generate_html_report(self, data: Dict) -> str:
        """
        ç”Ÿæˆä¸­æ–‡ HTML æŠ¥å‘Šï¼ˆè‡ªåŒ…å«æ ·å¼ï¼‰ã€‚
        data åŒ…å«ï¼š
          - json_file, xodr_file, threshold
          - report: QualityReportï¼ˆå« details.completeness / details.consistencyï¼‰
          - matching: analyze_matching_details() çš„è¿”å›
          - viz_path: å¯è§†åŒ–å›¾ç‰‡è·¯å¾„
          - max_detail_rows: åŒ¹é…æ˜ç»†æœ€å¤§å±•ç¤ºè¡Œæ•°
        """
        import html
        from datetime import datetime

        # å–å­—æ®µ
        json_file = html.escape(data["json_file"])
        xodr_file = html.escape(data["xodr_file"])
        threshold = data["threshold"]
        report: QualityReport = data["report"]
        matching = data["matching"]
        viz_path = data["viz_path"]
        max_rows = int(data.get("max_detail_rows", 200))

        # å®Œæ•´æ€§ç»†èŠ‚
        comp = report.details.get("completeness", {})
        lanes_info = comp.get("lanes", {})
        bounds_info = comp.get("bounds", {})
        objs_info = comp.get("objects", {})

        # ä¸€è‡´æ€§ç»†èŠ‚
        cons = report.details.get("consistency", {})
        avg_dev = cons.get("average_deviation", 0.0)
        max_dev = cons.get("max_deviation", 0.0)
        min_dev = cons.get("min_deviation", 0.0)
        pt_cnt = cons.get("point_count", 0)
        warn_cnt = cons.get("warnings_count", 0)
        over_cnt = cons.get("points_over_threshold", 0)

        # åŒ¹é…æ˜ç»†è¡¨æ ¼ï¼ˆé»˜è®¤å±•ç¤ºå‰ max_rows æ¡ï¼‰
        rows_html = []
        for row in matching.get("detailed_matches", [])[:max_rows]:
            jp = row["json_point"]
            nx, ny = (row["nearest_xodr_point"] or (None, None))
            rows_html.append(
                f"<tr>"
                f"<td class='num'>{row['index']}</td>"
                f"<td>{html.escape(jp.get('source', ''))}</td>"
                f"<td>({jp['x']:.3f}, {jp['y']:.3f})</td>"
                f"<td>{'(' + f'{nx:.3f}, {ny:.3f}' + ')' if nx is not None else 'â€”'}</td>"
                f"<td class='num'>{row['deviation']:.3f}</td>"
                f"<td>{html.escape(row['status'])}</td>"
                f"</tr>"
            )
        if not rows_html:
            rows_html.append("<tr><td colspan='6' style='text-align:center;'>æš‚æ— æ•°æ®</td></tr>")

        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Warningsï¼ˆæˆªæ–­å±•ç¤ºï¼‰
        warn_list_html = ""
        if report.warnings:
            warn_items = report.warnings[:200]
            warn_list_html = "<ul class='warning-list'>" + "".join(
                f"<li>{html.escape(w)}</li>" for w in warn_items
            ) + "</ul>"
            if len(report.warnings) > 200:
                warn_list_html += f"<p class='muted'>ï¼ˆä»…æ˜¾ç¤ºå‰ 200 æ¡ï¼Œå‰©ä½™ {len(report.warnings) - 200} æ¡å·²çœç•¥ï¼‰</p>"
        else:
            warn_list_html = "<p class='muted'>æ— </p>"

        # æ‹¼ HTML
        return f"""<!doctype html>
    <html lang="zh-CN">
    <head>
    <meta charset="utf-8" />
    <title>JSONâ†’XODR è´¨æ£€æŠ¥å‘Š</title>
    <style>
      html,body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans CJK SC", "Microsoft YaHei", "PingFang SC", sans-serif; color:#222; }}
      .container {{ max-width: 1100px; margin: 32px auto; padding: 0 16px; }}
      h1 {{ font-size: 26px; margin: 0 0 6px; }}
      h2 {{ font-size: 20px; margin: 28px 0 12px; border-left:4px solid #555; padding-left:8px; }}
      h3 {{ font-size: 16px; margin: 18px 0 10px; }}
      .meta, .muted {{ color:#666; font-size: 13px; }}
      .grid {{ display:grid; grid-template-columns: repeat(3,1fr); gap:12px; }}
      .card {{ border:1px solid #e6e6e6; border-radius:10px; padding:12px 14px; background:#fff; }}
      .kpi {{ font-size: 22px; font-weight:600; }}
      .ok {{ color:#138000; }}
      .warn {{ color:#d97706; }}
      .bad {{ color:#b91c1c; }}
      table {{ width:100%; border-collapse: collapse; }}
      th, td {{ border-bottom:1px solid #eee; padding:8px 10px; text-align:left; }}
      th {{ background:#fafafa; }}
      td.num, th.num {{ text-align:right; }}
      .imgwrap {{ text-align:center; margin: 14px 0 6px; }}
      .warning-list {{ margin:6px 0 0 16px; }}
      .tag {{ display:inline-block; padding:2px 6px; border-radius:6px; background:#f2f2f2; font-size:12px; margin-left:6px; }}
      .legend {{ color:#555; font-size: 13px; }}
      .footer {{ color:#777; font-size: 12px; margin-top: 28px; }}
    </style>
    </head>
    <body>
    <div class="container">

      <h1>JSON â†’ XODR è´¨æ£€æŠ¥å‘Š</h1>
      <div class="meta">ç”Ÿæˆæ—¶é—´ï¼š{now_str}</div>
      <div class="meta">JSON æ–‡ä»¶ï¼š{json_file}</div>
      <div class="meta">XODR æ–‡ä»¶ï¼š{xodr_file}</div>

      <h2>æ‘˜è¦</h2>
      <div class="grid">
        <div class="card">
          <div class="muted">å®Œæ•´æ€§å¾—åˆ†</div>
          <div class="kpi">{report.completeness_score:.1%}</div>
          <div class="legend">ä¾æ®ï¼šè½¦é“/è¾¹ç•Œ/ç‰©ä½“çš„æ•°é‡å¯¹æ¯”</div>
        </div>
        <div class="card">
          <div class="muted">ä¸€è‡´æ€§å¾—åˆ†</div>
          <div class="kpi">{report.consistency_score:.1%}</div>
          <div class="legend">ä¾æ®ï¼šä»…ä»¥ JSON è¾¹ç•Œç‚¹åˆ° XODRï¼ˆå‚è€ƒçº¿+è½¦é“è¾¹ç•Œï¼‰æœ€è¿‘è·ç¦»çš„å¹³å‡åç§»ä¸é˜ˆå€¼ï¼ˆ{threshold:.3f} mï¼‰æ¯”è¾ƒ</div>
        </div>
        <div class="card">
          <div class="muted">å‘Šè­¦æ•°é‡</div>
          <div class="kpi {'ok' if warn_cnt == 0 else 'warn' if warn_cnt < 10 else 'bad'}">{warn_cnt}</div>
          <div class="legend">è¶…é˜ˆå€¼ç‚¹ï¼š{over_cnt}/{pt_cnt}</div>
        </div>
      </div>

      <h2>å®Œæ•´æ€§æ£€æŸ¥</h2>
      <div class="card">
        <table>
          <thead>
            <tr><th>è¦ç´ </th><th class="num">JSON æ•°é‡</th><th class="num">XODR æ•°é‡</th><th class="num">å­åˆ†æ•°</th></tr>
          </thead>
          <tbody>
            <tr><td>è½¦é“ï¼ˆdrivingï¼‰</td><td class="num">{lanes_info.get('json_count', 'â€”')}</td><td class="num">{lanes_info.get('xodr_count', 'â€”')}</td><td class="num">{lanes_info.get('score', 0):.2f}</td></tr>
            <tr><td>è¾¹ç•Œ / æ ‡çº¿</td><td class="num">{bounds_info.get('json_count', 'â€”')}</td><td class="num">{bounds_info.get('xodr_count', 'â€”')}</td><td class="num">{bounds_info.get('score', 0):.2f}</td></tr>
            <tr><td>ç‰©ä½“ï¼ˆobjectsï¼‰</td><td class="num">{objs_info.get('json_count', 'â€”')}</td><td class="num">{objs_info.get('xodr_count', 'â€”')}</td><td class="num">{objs_info.get('score', 0):.2f}</td></tr>
          </tbody>
        </table>
        <div class="muted" style="margin-top:8px;">
            è¯´æ˜ï¼šXODR çš„æ•°é‡å¯èƒ½å¤§äº JSONï¼Œè¿™æ˜¯å› ä¸º OpenDRIVE ä¼šå°†è½¦é“ã€æ ‡çº¿æŒ‰æ®µè½æˆ–å±æ€§æ‹†åˆ†ï¼›åªè¦ä¸å°‘äº JSON å³è§†ä¸ºå®Œæ•´ã€‚
        </div>
      </div>

      <h2>ä¸€è‡´æ€§æ£€æŸ¥</h2>
      <div class="grid">
        <div class="card">
          <div class="muted">å¹³å‡åç§»</div>
          <div class="kpi">{avg_dev:.3f} m</div>
        </div>
        <div class="card">
          <div class="muted">æœ€å¤§ / æœ€å°åç§»</div>
          <div class="kpi">{max_dev:.3f} / {min_dev:.3f} m</div>
        </div>
        <div class="card">
          <div class="muted">å‚ä¸ç‚¹æ•°</div>
          <div class="kpi">{pt_cnt}</div>
          <div class="legend">ä»…åŒ…å« JSON ä¸­çš„è¾¹ç•Œç‚¹ï¼ˆobjects å·²å¿½ç•¥ï¼‰</div>
        </div>
      </div>

      <div class="card">
        <div class="muted">å¯è§†åŒ–ï¼ˆåˆ†å¸ƒ & åç§»çƒ­åŠ›ï¼‰</div>
        <div class="imgwrap">
          <img src="{html.escape(viz_path)}" alt="Visualization" style="max-width:100%;border:1px solid #eee;border-radius:8px;">
        </div>
        <div class="legend">å·¦å›¾ï¼šå‚è€ƒçº¿ + è½¦é“ä¸­å¿ƒçº¿/è¾¹ç•Œ + JSON ç‚¹ï¼›å³å›¾ï¼šä»…è¾¹ç•Œç‚¹åç§»ç€è‰²</div>
      </div>

      <h2>åŒ¹é…æ˜ç»†ï¼ˆå‰ {max_rows} æ¡ï¼‰<span class="tag">ä»… JSON è¾¹ç•Œç‚¹</span></h2>
      <div class="card">
        <table>
          <thead>
            <tr>
              <th class="num">åºå·</th>
              <th>ç±»å‹</th>
              <th>JSON åæ ‡ (x, y)</th>
              <th>æœ€è¿‘ XODR åæ ‡ (x, y)</th>
              <th class="num">åç§» (m)</th>
              <th>åˆ¤å®š</th>
            </tr>
          </thead>
          <tbody>
            {''.join(rows_html)}
          </tbody>
        </table>
        <div class="muted">æ€»è®¡ {matching.get('total_json_points', 0)} æ¡åŒ¹é…è®°å½•ï¼›ä¸ºé¿å…è¿‡å¤§ï¼Œä»…å±•ç¤ºå‰ {max_rows} æ¡ã€‚</div>
      </div>

      <h2>å‘Šè­¦åˆ—è¡¨ï¼ˆè¶…è¿‡é˜ˆå€¼çš„ç‚¹ï¼‰</h2>
      <div class="card">
        {warn_list_html}
      </div>

      <div class="footer">
        é˜ˆå€¼ï¼ˆæ¨ªå‘è·ç¦»ï¼‰ï¼š{threshold:.3f} mã€‚<br/>
        æ³¨ï¼šä¸€è‡´æ€§ä»…ä»¥ JSON çš„è¾¹ç•Œç‚¹å‚ä¸è®¡ç®—ï¼›JSON ä¸­ objects ä¸é“è·¯æ— ç›´æ¥å…³ç³»ï¼Œå·²åœ¨ç»Ÿè®¡å’Œå¯è§†åŒ–ä¸­å¿½ç•¥ã€‚
      </div>

    </div>
    </body>
    </html>"""


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºè´¨æ£€å™¨å®ä¾‹
    checker = QualityChecker(
        json_file="label3_2.json",
        xodr_file="label3_2.xodr",
        threshold=0.1  # 10cmé˜ˆå€¼
    )

    # æ‰§è¡Œè´¨æ£€
    completeness = checker.check_completeness()
    consistency = checker.check_curve_consistency()

    # è¯¦ç»†åˆ†æåŒ¹é…æƒ…å†µ
    analysis = checker.analyze_matching_details()

    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    viz_file = checker.visualize_point_matching()

    # ç”ŸæˆæŠ¥å‘Š
    report_file = checker.generate_report()

    print(f"\nğŸ“‹ Quality check summary:")
    print(f"   Completeness score: {completeness:.1%}")
    print(f"   Consistency score: {consistency:.1%}")
    print(f"   Warning count: {len(checker.report.warnings)}")
    print(f"   Visualization chart: {viz_file}")
    print(f"   Report file: {report_file}")