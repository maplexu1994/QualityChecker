#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSON to XODR Quality Checker
è´¨æ£€åˆä½œæ–¹çš„JSONè½¬XODRä»£ç å·¥å…·ï¼ˆå‚è€ƒçº¿ + è½¦é“è¾¹ç•Œé‡‡æ ·ï¼ŒæŒ‰ road åˆ†ç»„ç»˜åˆ¶ï¼‰
"""

import json
import xml.etree.ElementTree as ET
import numpy as np
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import math
import matplotlib.pyplot as plt


@dataclass
class QualityReport:
    """è´¨æ£€æŠ¥å‘Šæ•°æ®ç»“æ„"""
    completeness_score: float = 0.0
    consistency_score: float = 0.0
    warnings: List[str] = None
    details: Dict[str, Any] = None

    def __post_init__(self):
        if self.warnings is None:
            self.warnings = []
        if self.details is None:
            self.details = {}


class QualityChecker:
    """JSONè½¬XODRè´¨æ£€å·¥å…·ä¸»ç±»"""

    def __init__(self, json_file: str, xodr_file: str, threshold: float = 0.1):
        """
        åˆå§‹åŒ–è´¨æ£€å™¨
        """
        self.json_file = Path(json_file)
        self.xodr_file = Path(xodr_file)
        self.threshold = threshold

        # åŠ è½½æ•°æ®
        self.json_data = self._load_json()
        self.xodr_data = self._load_xodr()

        # åˆå§‹åŒ–æŠ¥å‘Š
        self.report = QualityReport()

    # ----------------------------
    # åŸºç¡€åŠ è½½
    # ----------------------------
    def _load_json(self) -> Dict:
        """åŠ è½½JSONæ•°æ®"""
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½JSONæ–‡ä»¶: {self.json_file}")
            return data
        except Exception as e:
            raise ValueError(f"âŒ æ— æ³•åŠ è½½JSONæ–‡ä»¶ {self.json_file}: {e}")

    def _load_xodr(self) -> ET.Element:
        """åŠ è½½XODRæ•°æ®"""
        try:
            tree = ET.parse(self.xodr_file)
            root = tree.getroot()
            print(f"âœ… æˆåŠŸåŠ è½½XODRæ–‡ä»¶: {self.xodr_file}")
            return root
        except Exception as e:
            raise ValueError(f"âŒ æ— æ³•åŠ è½½XODRæ–‡ä»¶ {self.xodr_file}: {e}")

    # ----------------------------
    # å®Œæ•´æ€§æ£€æŸ¥
    # ----------------------------
    def check_completeness(self) -> float:
        """
        æ£€æŸ¥å…ƒç´ å®Œæ•´æ€§ï¼šå¯¹æ¯”JSONè¾“å…¥å’ŒXODRè¾“å‡ºçš„å…³é”®å…ƒç´ æ•°é‡
        """
        print("\nğŸ” å¼€å§‹å…ƒç´ å®Œæ•´æ€§æ£€æŸ¥...")

        completeness_details = {}
        total_score = 0
        check_count = 0

        # 1) è½¦é“æ•°é‡
        json_lanes = len(self.json_data.get('lanes', []))
        xodr_lanes = self._count_xodr_lanes()
        lane_score = min(xodr_lanes / json_lanes, 1.0) if json_lanes > 0 else 1.0
        completeness_details['lanes'] = {'json_count': json_lanes, 'xodr_count': xodr_lanes, 'score': lane_score}
        total_score += lane_score
        check_count += 1

        # 2) è¾¹ç•Œæ•°é‡ï¼ˆç²—ç•¥ç”¨ roadMark æ•°é‡è¿‘ä¼¼ï¼‰
        json_bounds = len(self.json_data.get('bounds', []))
        xodr_road_marks = self._count_xodr_road_marks()
        bound_score = min(xodr_road_marks / (json_bounds * 2), 1.0) if json_bounds > 0 else 1.0
        completeness_details['bounds'] = {'json_count': json_bounds, 'xodr_count': xodr_road_marks, 'score': bound_score}
        total_score += bound_score
        check_count += 1

        # 3) ç‰©ä½“æ•°é‡
        json_objects = len(self.json_data.get('objects', []))
        xodr_objects = self._count_xodr_objects()
        object_score = min(xodr_objects / json_objects, 1.0) if json_objects > 0 else 1.0
        completeness_details['objects'] = {'json_count': json_objects, 'xodr_count': xodr_objects, 'score': object_score}
        total_score += object_score
        check_count += 1

        # æ€»ä½“å¾—åˆ†
        self.report.completeness_score = total_score / check_count if check_count > 0 else 0
        self.report.details['completeness'] = completeness_details
        print(f"ğŸ“Š å®Œæ•´æ€§æ£€æŸ¥å®Œæˆï¼Œæ€»ä½“å¾—åˆ†: {self.report.completeness_score:.2%}")
        return self.report.completeness_score

    # ----------------------------
    # ä¸€è‡´æ€§æ£€æŸ¥
    # ----------------------------
    def check_curve_consistency(self) -> float:
        """
        æ£€æŸ¥æ›²çº¿ä¸€è‡´æ€§ï¼šå¯¹æ¯”XODRå‚è€ƒçº¿/è½¦é“è¾¹ç•Œä¸JSONåæ ‡ç‚¹çš„åç§»
        """
        print("\nğŸ” å¼€å§‹æ›²çº¿ä¸€è‡´æ€§æ£€æŸ¥...")

        # JSON ç‚¹
        all_json_points = self._get_all_json_points()

        # XODR ç‚¹ï¼ˆå‚è€ƒçº¿ + è½¦é“è¾¹ç•Œï¼‰
        xodr_data = self._sample_xodr_curves_and_lanes()
        xodr_points: List[Tuple[float, float]] = []
        # åˆå¹¶å‚è€ƒçº¿
        xodr_points.extend(xodr_data.get("reference_lines", []))
        # åˆå¹¶æ‰€æœ‰è¾¹ç•Œå¤šæŠ˜çº¿
        for pts in xodr_data.get("lane_boundaries", {}).values():
            xodr_points.extend(pts)

        print(f"   ğŸ“ JSONæ€»åæ ‡ç‚¹æ•°: {len(all_json_points)}")
        print(f"   ğŸ“ XODRé‡‡æ ·ç‚¹æ•°: {len(xodr_points)} "
              f"(ref: {sum(len(v) for v in xodr_data.get('reference_by_road', {}).values())}, "
              f"lanes polylines: {len(xodr_data.get('lane_boundaries', {}))})")

        if not xodr_points:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°XODRé‡‡æ ·ç‚¹")
            return 0.0

        # è®¡ç®—æ¯ä¸ª JSON ç‚¹åˆ° XODR çš„æœ€è¿‘è·ç¦»
        deviations = []
        warnings = []
        for i, json_point in enumerate(all_json_points):
            min_distance = self._find_nearest_distance_to_xodr(json_point, xodr_points)
            deviations.append(min_distance)
            if min_distance > self.threshold:
                warnings.append(
                    f"âš ï¸ åæ ‡ç‚¹ ({json_point['x']:.1f}, {json_point['y']:.1f}) åç§»è¶…è¿‡é˜ˆå€¼: {min_distance:.3f}m > {self.threshold}m"
                )
            if (i + 1) % 100 == 0 or i == len(all_json_points) - 1:
                print(f"   ğŸ“Š å·²å¤„ç† {i + 1}/{len(all_json_points)} ä¸ªç‚¹")

        # ç»Ÿè®¡ä¸å¾—åˆ†
        avg_deviation = float(np.mean(deviations)) if deviations else 0.0
        max_deviation = float(np.max(deviations)) if deviations else 0.0
        min_deviation = float(np.min(deviations)) if deviations else 0.0
        point_count = len(deviations)
        consistency_score = max(0, 1 - (avg_deviation / self.threshold)) if self.threshold > 0 else 0

        self.report.consistency_score = consistency_score
        self.report.warnings.extend(warnings)
        self.report.details['consistency'] = {
            'average_deviation': avg_deviation,
            'max_deviation': max_deviation,
            'min_deviation': min_deviation,
            'point_count': point_count,
            'threshold': self.threshold,
            'warnings_count': len(warnings),
            'points_over_threshold': sum(1 for d in deviations if d > self.threshold)
        }

        print(f"ğŸ“Š ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼Œå¾—åˆ†: {consistency_score:.2%}")
        print(f"ğŸ“Š å¹³å‡åç§»: {avg_deviation:.3f}mï¼Œæœ€å¤§åç§»: {max_deviation:.3f}mï¼Œæœ€å°åç§»: {min_deviation:.3f}m")
        print(f"ğŸ“Š è¶…è¿‡é˜ˆå€¼çš„ç‚¹: {self.report.details['consistency']['points_over_threshold']}/{point_count}")
        return consistency_score

    # ----------------------------
    # JSON / XODR é‡‡æ ·ä¸å‡ ä½•
    # ----------------------------
    def _get_all_json_points(self) -> List[Dict]:
        """è·å–JSONä¸­æ‰€æœ‰çš„åæ ‡ç‚¹"""
        all_points = []

        # bounds
        for bound in self.json_data.get('bounds', []):
            bound_id = bound.get('id', '')
            for pt in bound.get('pts', []):
                all_points.append({
                    'x': pt['x'],
                    'y': pt['y'],
                    'z': pt.get('z', 0),
                    'bound_id': bound_id,
                    'source': 'bound'
                })

        # objectsï¼ˆå¯é€‰ï¼‰
        for obj in self.json_data.get('objects', []):
            obj_id = obj.get('id', '')
            for pt in obj.get('outline', []):
                all_points.append({
                    'x': pt['x'],
                    'y': pt['y'],
                    'z': pt.get('z', 0),
                    'object_id': obj_id,
                    'source': 'object'
                })

        return all_points

    # ====== å‚è€ƒçº¿ + è½¦é“è¾¹ç•Œç»Ÿé‡‡ï¼ˆæŒ‰ road åˆ†ç»„ï¼‰======
    def _sample_xodr_curves_and_lanes(self, samples_per_geometry: int = 200) -> Dict:
        """
        è¿”å›:
        {
            "reference_by_road": {road_id: [(x,y), ...], ...},
            "reference_lines": [(x,y), ...],         # æ‰å¹³åŒ–åˆé›†ï¼Œä¾¿äºå¿«é€Ÿä½¿ç”¨
            "lane_boundaries": {"road{rid}_L1": [(x,y),...], "road{rid}_R1": [...], ...}
        }
        """
        root = self.xodr_data
        out_ref_by_road: Dict[str, List[Tuple[float, float]]] = {}
        out_lane_boundaries: Dict[str, List[Tuple[float, float]]] = {}

        # éå†æ¯æ¡ road
        for road in root.findall('./road'):
            rid = road.get('id', '?')

            # ---- 1) é‡‡æ ·å‚è€ƒçº¿ï¼ˆå¸¦ sã€headingï¼‰----
            ref_samples = self._sample_road_reference_with_heading(road, samples_per_geometry)
            ref_pts = [(p['x'], p['y']) for p in ref_samples]
            out_ref_by_road[rid] = ref_pts

            # ---- 2) laneOffset piecewise å¤šé¡¹å¼ ----
            lane_offsets = []
            for lo in road.findall('./laneOffset'):
                lane_offsets.append({
                    's': float(lo.get('s', 0)),
                    'a': float(lo.get('a', 0)),
                    'b': float(lo.get('b', 0)),
                    'c': float(lo.get('c', 0)),
                    'd': float(lo.get('d', 0)),
                })
            lane_offsets.sort(key=lambda e: e['s'])

            # ---- 3) laneSection & lanes ----
            lanes_node = road.find('./lanes')
            if lanes_node is None or not ref_samples:
                continue

            lane_sections = lanes_node.findall('./laneSection')
            lane_sections.sort(key=lambda s: float(s.get('s', 0.0)))
            road_end_s = ref_samples[-1]['s']

            # ä¸ºäº†è¿ç»­ç»˜åˆ¶è¾¹ç•Œï¼Œåˆ›å»ºä¸€ä¸ªâ€œè¾¹ç•Œè½¨è¿¹ç¼“å­˜â€å­—å…¸ï¼ˆä»…åœ¨å½“å‰ road å†…ï¼‰
            boundary_traces: Dict[str, List[Tuple[float, float]]] = {}

            for si, sec in enumerate(lane_sections):
                s_start = float(sec.get('s', 0.0))
                s_end = float(lane_sections[si + 1].get('s', road_end_s)) if si + 1 < len(lane_sections) else road_end_s

                # section å†…å‚è€ƒç‚¹
                sec_samples = [p for p in ref_samples if s_start - 1e-6 <= p['s'] <= s_end + 1e-6]
                if not sec_samples:
                    continue

                # å·¦å³è½¦é“
                left_node = sec.find('./left')
                right_node = sec.find('./right')

                # è§£æ lane -> widths piecewise
                def _collect_lanes(node, side: str):
                    lanes = []
                    if node is None:
                        return lanes
                    for ln in node.findall('./lane'):
                        lane_id = int(ln.get('id', 0))
                        widths = []
                        for w in ln.findall('./width'):
                            widths.append({
                                'sOffset': float(w.get('sOffset', 0)),
                                'a': float(w.get('a', 0)),
                                'b': float(w.get('b', 0)),
                                'c': float(w.get('c', 0)),
                                'd': float(w.get('d', 0)),
                            })
                        widths.sort(key=lambda e: e['sOffset'])
                        if (side == 'L' and lane_id > 0) or (side == 'R' and lane_id < 0):
                            lanes.append({'id': abs(lane_id), 'widths': widths})
                    lanes.sort(key=lambda L: L['id'])
                    return lanes

                left_lanes = _collect_lanes(left_node, 'L')   # id: 1,2,3...
                right_lanes = _collect_lanes(right_node, 'R') # id: 1,2,3...

                for p in sec_samples:
                    s = p['s']; x_c, y_c, hdg = p['x'], p['y'], p['hdg']
                    lane_off = self._eval_piecewise_poly(lane_offsets, s)

                    # å·¦ä¾§ï¼šä»ä¸­å¿ƒçº¿å‘å¤–ç´¯åŠ 
                    cum = lane_off
                    for lane in left_lanes:
                        w = self._eval_lane_width_at(lane['widths'], s - s_start)
                        boundary_offset = cum + w
                        bx, by = self._offset_point_normal(x_c, y_c, hdg, boundary_offset)
                        key = f"road{rid}_L{lane['id']}"
                        boundary_traces.setdefault(key, []).append((bx, by))
                        cum += w

                    # å³ä¾§ï¼šä»ä¸­å¿ƒçº¿å‘å¤–ç´¯åŠ ï¼ˆè´Ÿå‘ï¼‰
                    cum = lane_off
                    for lane in right_lanes:
                        w = self._eval_lane_width_at(lane['widths'], s - s_start)
                        boundary_offset = cum - w
                        bx, by = self._offset_point_normal(x_c, y_c, hdg, boundary_offset)
                        key = f"road{rid}_R{lane['id']}"
                        boundary_traces.setdefault(key, []).append((bx, by))
                        cum -= w

            # å°†å½“å‰ road çš„è¾¹ç•ŒåŠ å…¥æ€»è¾“å‡ºï¼ˆä¸åŒ road çš„åŒåè½¦é“ä¸å†è¢«ä¸²æ¥ï¼‰
            for key, pts in boundary_traces.items():
                if len(pts) >= 2:
                    out_lane_boundaries[key] = pts

        # æ‰å¹³åŒ–å‚è€ƒçº¿åˆé›†ï¼ˆä»…ç”¨äºæœ€è¿‘é‚»/èƒŒæ™¯æ•£ç‚¹ï¼‰
        ref_all = [pt for pts in out_ref_by_road.values() for pt in pts]

        return {
            "reference_by_road": out_ref_by_road,
            "reference_lines": ref_all,
            "lane_boundaries": out_lane_boundaries
        }

    # ====== å‚è€ƒçº¿é‡‡æ ·ï¼šè¿”å›åŒ…å« s, x, y, hdg çš„åˆ—è¡¨ ======
    def _sample_road_reference_with_heading(self, road: ET.Element, samples_per_geometry: int) -> List[Dict]:
        pts = []
        plan = road.find('./planView')
        if plan is None:
            return pts

        for geom in plan.findall('./geometry'):
            s0 = float(geom.get('s', 0))
            x0 = float(geom.get('x', 0))
            y0 = float(geom.get('y', 0))
            hdg0 = float(geom.get('hdg', 0))
            length = float(geom.get('length', 0))

            children = list(geom)
            if not children:
                continue
            g = children[0]
            tag = g.tag

            def local_to_global(u, v, hdg_base):
                x = x0 + math.cos(hdg_base) * u - math.sin(hdg_base) * v
                y = y0 + math.sin(hdg_base) * u + math.cos(hdg_base) * v
                return x, y

            # å‡åŒ€æŒ‰å¼§é•¿é‡‡æ ·
            for i in range(samples_per_geometry + 1):
                u = length * (i / samples_per_geometry)  # å±€éƒ¨å¼§é•¿
                s = s0 + u

                if tag == 'line':
                    x, y = local_to_global(u, 0.0, hdg0)
                    hdg = hdg0

                elif tag == 'arc':
                    curvature = float(g.get('curvature', 0))
                    angle = curvature * u
                    R = 1.0 / curvature if abs(curvature) > 1e-12 else 1e12
                    lx = R * math.sin(angle)
                    lv = R * (1 - math.cos(angle))
                    x, y = local_to_global(lx, lv, hdg0)
                    hdg = hdg0 + angle

                elif tag == 'spiral':
                    k0 = float(g.get('curvStart', 0))
                    k1 = float(g.get('curvEnd', 0))
                    dk = (k1 - k0) / length if length > 0 else 0.0
                    theta = k0 * u + 0.5 * dk * (u ** 2)  # âˆ«k(s)ds
                    lx = u * math.cos(theta / 2.0)
                    lv = u * math.sin(theta / 2.0)
                    x, y = local_to_global(lx, lv, hdg0)
                    hdg = hdg0 + theta

                elif tag == 'paramPoly3':
                    aU = float(g.get('aU', 0)); bU = float(g.get('bU', 1)); cU = float(g.get('cU', 0)); dU = float(g.get('dU', 0))
                    aV = float(g.get('aV', 0)); bV = float(g.get('bV', 0)); cV = float(g.get('cV', 0)); dV = float(g.get('dV', 0))
                    p_range = g.get('pRange', 'normalized')
                    t = (i / samples_per_geometry) if p_range != 'arcLength' else (u / length if length > 0 else 0.0)
                    uu = aU + bU*t + cU*t*t + dU*t*t*t
                    vv = aV + bV*t + cV*t*t + dV*t*t*t
                    x, y = local_to_global(uu, vv, hdg0)
                    du = bU + 2*cU*t + 3*dU*t*t
                    dv = bV + 2*cV*t + 3*dV*t*t
                    hdg = hdg0 + math.atan2(dv, du if abs(du) > 1e-12 else 1e-12)

                else:
                    x, y = local_to_global(u, 0.0, hdg0)
                    hdg = hdg0

                pts.append({'s': s, 'x': x, 'y': y, 'hdg': hdg})

        pts.sort(key=lambda d: d['s'])
        return pts

    # ====== piecewise polynomial & åç§» ======
    @staticmethod
    def _eval_piecewise_poly(segments: List[Dict], s: float) -> float:
        if not segments:
            return 0.0
        seg = None
        for cand in segments:
            if s + 1e-9 >= cand['s']:
                seg = cand
            else:
                break
        if seg is None:
            seg = segments[0]
        ds = max(0.0, s - seg['s'])
        return seg['a'] + seg['b']*ds + seg['c']*ds*ds + seg['d']*ds*ds*ds

    @staticmethod
    def _eval_lane_width_at(width_segs: List[Dict], s_rel: float) -> float:
        if not width_segs:
            return 0.0
        seg = None
        for w in width_segs:
            if s_rel + 1e-9 >= w['sOffset']:
                seg = w
            else:
                break
        if seg is None:
            seg = width_segs[0]
        ds = max(0.0, s_rel - seg['sOffset'])
        return seg['a'] + seg['b']*ds + seg['c']*ds*ds + seg['d']*ds*ds*ds

    @staticmethod
    def _offset_point_normal(x: float, y: float, hdg: float, v: float) -> Tuple[float, float]:
        nx = -math.sin(hdg)
        ny =  math.cos(hdg)
        return x + v * nx, y + v * ny

    # ----------------------------
    # è·ç¦»/å¯è§†åŒ–
    # ----------------------------
    @staticmethod
    def _find_nearest_distance_to_xodr(json_point: Dict, xodr_points: List[Tuple[float, float]]) -> float:
        jx, jy = json_point['x'], json_point['y']
        min_d2 = float('inf')
        for xx, yy in xodr_points:
            dx = jx - xx; dy = jy - yy
            d2 = dx*dx + dy*dy
            if d2 < min_d2:
                min_d2 = d2
        return math.sqrt(min_d2) if min_d2 < float('inf') else float('inf')

    def visualize_point_matching(self, save_path: str = None) -> str:
        """ç»˜åˆ¶ï¼šå·¦-æ€»ä½“åˆ†å¸ƒï¼›å³-åç§»åˆ†æ"""
        print("\nğŸ¨ Generating visualization charts...")

        all_json_points = self._get_all_json_points()
        xodr_data = self._sample_xodr_curves_and_lanes()

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

        # å·¦å›¾ï¼šæ€»ä½“åˆ†å¸ƒï¼ˆå‚è€ƒçº¿ç”»çº¿æ®µï¼›è½¦é“è¾¹ç•ŒæŒ‰å„è‡ªæŠ˜çº¿ç”»ï¼‰
        self._plot_overall_distribution(ax1, all_json_points, xodr_data)

        # å³å›¾ï¼šåç§»åˆ†æï¼ˆå‚è€ƒçº¿+æ‰€æœ‰è¾¹ç•Œä½œä¸ºå¯¹æ¯”åŸºå‡†ï¼‰
        xodr_points = []
        xodr_points.extend(xodr_data.get("reference_lines", []))
        for pts in xodr_data.get("lane_boundaries", {}).values():
            xodr_points.extend(pts)
        self._plot_deviation_analysis(ax2, all_json_points, xodr_points)

        plt.tight_layout()
        if save_path is None:
            save_path = self.json_file.parent / f"{self.json_file.stem}_visualization.png"
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… Visualization chart saved: {save_path}")
        try:
            plt.show()
        except Exception:
            pass
        return str(save_path)

    def _plot_overall_distribution(self, ax, json_points: List[Dict], xodr_data: Dict):
        """Plot overall point distribution"""

        # 1) å‚è€ƒçº¿ï¼šæŒ‰ road åˆ†åˆ«è¿çº¿
        refs_by_road = xodr_data.get("reference_by_road", {})
        for i, (rid, pts) in enumerate(refs_by_road.items()):
            if len(pts) >= 2:
                xs, ys = zip(*pts)
                ax.plot(xs, ys, color='skyblue', linewidth=1.4, alpha=0.9,
                        label='XODR reference' if i == 0 else None)

        # 2) è½¦é“è¾¹ç•Œï¼ˆå¤šæ¡æŠ˜çº¿ï¼›ä¸åŒ road + è½¦é“ç‹¬ç«‹ï¼‰
        lane_bd = xodr_data.get("lane_boundaries", {})
        if lane_bd:
            colors = plt.cm.tab20(np.linspace(0, 1, max(2, len(lane_bd))))
            for idx, (key, pts) in enumerate(lane_bd.items()):
                if len(pts) < 2:
                    continue
                xs, ys = zip(*pts)
                # åªè®©ç¬¬ä¸€æ¡è¿›å…¥å›¾ä¾‹ï¼Œé¿å…è¿‡é•¿
                ax.plot(xs, ys, linewidth=1.6, color=colors[idx % len(colors)], alpha=0.95,
                        label='XODR lane R/L' if idx == 0 else None)

        # 3) JSON è¾¹ç•Œç‚¹
        bound_points = [p for p in json_points if p['source'] == 'bound']
        if bound_points:
            bx = [p['x'] for p in bound_points]; by = [p['y'] for p in bound_points]
            ax.scatter(bx, by, c='red', s=28, alpha=0.9, label=f'JSON bounds ({len(bound_points)})')

        # 4) JSON ç‰©ä½“ç‚¹
        obj_points = [p for p in json_points if p['source'] == 'object']
        if obj_points:
            ox = [p['x'] for p in obj_points]; oy = [p['y'] for p in obj_points]
            ax.scatter(ox, oy, c='orange', s=28, alpha=0.9, label=f'JSON objects ({len(obj_points)})')

        ax.set_xlabel('X (m)'); ax.set_ylabel('Y (m)')
        ax.set_title('JSON vs XODR Distribution')
        ax.grid(True, alpha=0.3); ax.axis('equal')
        ax.legend()

    def _plot_deviation_analysis(self, ax, json_points: List[Dict], xodr_points: List[Tuple[float, float]]):
        """Plot deviation analysisï¼ˆä»¥æ‰€æœ‰ XODR ç‚¹ä½œä¸ºåŸºå‡†ï¼‰"""
        deviations = [self._find_nearest_distance_to_xodr(p, xodr_points) for p in json_points]
        json_x = [p['x'] for p in json_points]
        json_y = [p['y'] for p in json_points]

        # èƒŒæ™¯ï¼šXODR å¯†é›†ç‚¹
        if xodr_points:
            xp, yp = zip(*xodr_points)
            ax.scatter(xp, yp, c='lightgray', s=3, alpha=0.35, label='XODR samples')

        # JSON ç‚¹æŒ‰åç§»ç€è‰²
        scatter = ax.scatter(json_x, json_y, c=deviations, s=50,
                             cmap='RdYlGn_r', alpha=0.9, edgecolors='black', linewidth=0.4)

        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('Deviation (m)')

        stats_text = f"""Statistics:
Total points: {len(json_points)}
Avg deviation: {np.mean(deviations):.3f}m
Max deviation: {np.max(deviations):.3f}m
Min deviation: {np.min(deviations):.3f}m
Over threshold: {sum(1 for d in deviations if d > self.threshold)}/{len(deviations)}"""
        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.85))

        ax.set_xlabel('X (m)'); ax.set_ylabel('Y (m)')
        ax.set_title(f'Deviation Analysis (Avg: {np.mean(deviations):.3f}m)')
        ax.grid(True, alpha=0.3); ax.axis('equal')
        ax.legend()

    # ----------------------------
    # ç»Ÿè®¡è®¡æ•°
    # ----------------------------
    def _count_xodr_lanes(self) -> int:
        """ç»Ÿè®¡XODRä¸­çš„è½¦é“æ•°é‡ï¼ˆè¡Œè½¦é“ï¼‰"""
        count = 0
        for road in self.xodr_data.findall('./road'):
            lanes_node = road.find('./lanes')
            if lanes_node is None:
                continue
            for lane in lanes_node.findall('.//lane'):
                if lane.get('type') == 'driving':
                    count += 1
        return count

    def _count_xodr_road_marks(self) -> int:
        """ç»Ÿè®¡XODRä¸­çš„é“è·¯æ ‡è®°æ•°é‡ï¼ˆç²—ç•¥ï¼‰"""
        return len(self.xodr_data.findall('.//roadMark'))

    def _count_xodr_objects(self) -> int:
        """ç»Ÿè®¡XODRä¸­çš„ç‰©ä½“æ•°é‡"""
        return len(self.xodr_data.findall('.//object'))

    # ----------------------------
    # æŠ¥å‘Šï¼ˆå ä½ï¼‰
    # ----------------------------
    def generate_report(self) -> str:
        """ç”Ÿæˆè´¨æ£€æŠ¥å‘Šï¼ˆå ä½å®ç°ï¼‰"""
        print("\nğŸ“ ç”Ÿæˆè´¨æ£€æŠ¥å‘Š...")
        if self.report.completeness_score == 0:
            self.check_completeness()
        if self.report.consistency_score == 0:
            self.check_curve_consistency()
        html_report = self._generate_html_report()
        report_file = self.json_file.parent / f"{self.json_file.stem}_quality_report.html"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_report)
        print(f"âœ… è´¨æ£€æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        return str(report_file)

    @staticmethod
    def _generate_html_report() -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Šï¼ˆå ä½ï¼‰"""
        return "<html><body><h1>è´¨æ£€æŠ¥å‘Šç”Ÿæˆä¸­...</h1></body></html>"


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    checker = QualityChecker(
        json_file="../src/sample_objects.json",
        xodr_file="../src/sample_objects.xodr",
        threshold=0.1  # 10cmé˜ˆå€¼
    )

    # æ‰§è¡Œè´¨æ£€
    completeness = checker.check_completeness()
    consistency = checker.check_curve_consistency()

    # å¯è§†åŒ–
    viz_file = checker.visualize_point_matching()

    # æŠ¥å‘Š
    report_file = checker.generate_report()

    print(f"\nğŸ“‹ Quality check summary:")
    print(f"   Completeness score: {completeness:.1%}")
    print(f"   Consistency score: {consistency:.1%}")
    print(f"   Warning count: {len(checker.report.warnings)}")
    print(f"   Visualization chart: {viz_file}")
    print(f"   Report file: {report_file}")
